"""dataset for training in pytorch"""
import miniosl
import torch
import numpy as np
import logging
import os
import os.path
from typing import Tuple


class PositionwiseDataset(torch.utils.data.Dataset):
    """positionwise data implementing `torch.utils.data.Dataset`

    :param filename: path to `.npz` file containing np.array \
    generated by :py:func:`sfen_file_to_training_np_array`

    .. note:: suggest using :py:class:`GameDataset` instead
    """
    def __init__(self, filename):
        dict = np.load(filename)
        keys = list(dict.keys())
        if len(keys) != 1:
            logging.warning(f'expect single key {keys}')
        self.data = dict[keys[0]]
        logging.info(f'load {len(self.data)} data {keys[0]} from {filename}')

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.policy_item_with_aux(idx)

    def policy_item_with_aux(self,
                             idx: int) -> Tuple[torch.Tensor, int, np.float32,
                                                torch.Tensor]:
        item = miniosl.to_state_label_tuple320(self.data[idx])
        input, move_label, value_label, aux_label = item.to_np_feature_labels()
        return torch.from_numpy(input), move_label, np.float32(value_label), torch.from_numpy(aux_label)

    def raw_data320(self, idx):
        return miniosl.to_state_label_tuple320(self.data[idx])


def load_sfen_from_file(sfen, *,
                        compress_and_rm: bool = False, strict: bool = False
                        ) -> list[miniosl.SubRecord]:
    """load game records from file for `GameRecordBlock`

    games must be completed to serve as training data.
    """
    sfen_npz = ''
    if sfen.endswith('.npz'):
        sfen_npz = sfen
    elif os.path.isfile(f'{sfen}.npz'):
        sfen_npz = f'{sfen}.npz'
    if os.path.isfile(sfen_npz):
        with open(sfen_npz, 'r') as f:
            record_set = miniosl.RecordSet.from_npz(sfen_npz)
            return [miniosl.SubRecord(_) for _ in record_set.records]
    data = []
    ignored = 0
    with open(f'{sfen}', 'r') as f:
        for line in f:
            line = line.strip()
            record = miniosl.usi_record(line)
            if record.result == miniosl.InGame:
                if strict:
                    logging.warning(f'in game {line}')
                    raise ValueError('in game')
                ignored += 1
                continue
            data.append(record)
        if compress_and_rm:
            record_set = miniosl.RecordSet(data)
            record_set.save_npz(f'{sfen}.npz')
            os.remove(f'{sfen}')
    return [miniosl.SubRecord(_) for _ in data]


class GameRecordBlock:
    """a batch of game records (e.g., 20k)

    :param sfen: path to sfen file or list of :py:class:`miniosl.SubRecord`
    """
    def __init__(self, sfen: str | list[miniosl.SubRecord]):
        if isinstance(sfen, str):
            self.data = load_sfen_from_file(sfen,
                                            compress_and_rm=True, strict=True)
        elif isinstance(sfen, list):
            self.data = sfen

    def sample(self, index):
        if not (0 <= index < len(self.data)):
            raise ValueError("index")
        return self.data[index].sample_feature_labels()

    def __len__(self):
        return len(self.data)


class GameDataset(torch.utils.data.Dataset):
    """dataset for training.

    - sample position by game index \
      (a random position in the game record is returned)
    - keep the latest `GameRecordBlock` s (e.g., 50) as in MuZero

    :param window_size: number of game records to keep
    :param block_unit: number of game records for a block, \
    that is a unit in add/replace oporation
    """
    def __init__(self, window_size, block_unit):
        self.window_size = window_size
        self.block_unit = block_unit
        self.blocks = []
        self.cur_block_id = 0
        self.block_limit = (window_size + block_unit - 1) // block_unit

    def block_id(self) -> int:
        """number of block added so far"""
        return self.cur_block_id

    def unit_size(self) -> int:
        """number of records in a `GameRecordBlock`"""
        return self.block_unit

    def add(self, new_block):
        """add or replace the oldest one with `new_block`"""
        if len(new_block) < self.unit_size():
            raise ValueError(f'size error {len(new_block)} {self.block_unit}')

        if len(self.blocks) < self.block_limit:
            self.blocks.append(new_block)
        else:
            self.blocks[self.cur_block_id % self.block_limit] = new_block
        self.cur_block_id += 1

    def stored_game_records(self):
        return self.block_unit * len(self.blocks)

    def sample(self, index):
        if not (0 <= index < len(self)):
            raise ValueError("index")
        # need this due to the spec of __len__(), even after fully filled
        index %= self.stored_game_records()
        p, s = index // self.block_unit, index % self.block_unit
        return self.blocks[p].sample(s)

    def __len__(self):
        """epoch should go beyond #records and #positions"""
        return self.stored_game_records() * 100

    def __getitem__(self, idx):
        return self.reshape_item(self.sample(idx))

    def reshape_item(self, item):
        input, move_label, value_label, aux_label = item
        return (torch.from_numpy(input), move_label, np.float32(value_label),
                torch.from_numpy(aux_label))


def load_torch_dataset(path: str) -> torch.utils.data.Dataset:
    """load dataset from file"""
    if path.endswith('.sfen') or path.endswith('.txt') or path.endswith('sfen.npz'):
        # use entire file as a single block
        seq = load_sfen_from_file(path, compress_and_rm=False, strict=False)
        block = GameRecordBlock(seq)
        n = len(block.data)
        set = GameDataset(n, n)
        set.add(block)
        return set
    if path.endswith('.npz'):
        return PositionwiseDataset(path)
    raise ValueError(f'unsupported data {path}')
